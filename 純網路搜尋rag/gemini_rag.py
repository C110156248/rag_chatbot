import google.generativeai as genai
import streamlit as st
from dotenv import load_dotenv
from googleapiclient.discovery import build
import os
def generate_gemini_response(model_name, llm_input, api_key):# Gemini API
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name=model_name)
    try:
        response = model.generate_content(llm_input)
        return response.text
    except Exception as e:
        print(f"Error during Gemini response generation: {e}")
        return None
def search_google_custom(query, api_key, cse_id, num_results):# Custom Search API
    service = build("customsearch", "v1", developerKey=api_key)
    try:
      response = (
          service.cse()
          .list(q=query, cx=cse_id, num=num_results)
          .execute()
      )
      results = response.get("items", []) 
      formatted_results = []
      for item in results:
          formatted_results.append({
              "title": item.get("title", ""),
              "link": item.get("link", ""),
              "snippet": item.get("snippet", "")
          })
      return formatted_results
    except Exception as e:
        print(f"Error during Google Custom Search: {e}")
        return []
def rag_output(prompt, api_key, search_engine_id, cse_id, model_name): # RAG
    search_results=search_google_custom(prompt, search_engine_id, cse_id, 5)
    Retrieval_content = "é€™æ˜¯ç¶²è·¯ä¸Šæœå°‹åˆ°çš„è³‡æ–™å¯ä¾›åƒè€ƒ:\n"
    for i, result in enumerate(search_results):
      Retrieval_content += f"æ¨™é¡Œï¼š{result['title']}\n"
      Retrieval_content += f"æ‘˜è¦ï¼š{result['snippet']}\n"
    response = generate_gemini_response(model_name, prompt, api_key)
    return response
def main_response(text):
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()
    gemini_key = os.getenv('gemini_key')
    search_engine_id = os.getenv('google_search_api')
    cse_id = os.getenv('google_CSE_ID')
    model_name = "gemini-1.5-flash"
    #rag
    user_query = text
    llm_input = f"æ ¹æ“šè¦æ±‚ï¼Œåˆ†æéœ€è¦ä¸Šç¶²æŸ¥è©¢çš„è³‡è¨Š(å…§éƒ¨çŸ¥è­˜ä¸è¶³å¤ )ã€‚ç”Ÿæˆéœ€è¦ä¸Šç¶²æŸ¥è©¢è³‡è¨Šçš„çš„é—œéµå­—(ä¸éœ€è¦ç›¸é—œèªªæ˜ï¼Œå›å‚³è³‡æ–™å¯ä»¥ç›´æ¥è¤‡è£½ã€è²¼ä¸Šä½¿ç”¨): {user_query} "
    Google_Search_Keywords = generate_gemini_response(model_name, prompt, gemini_key)
    search_results = search_google_custom(Google_Search_Keywords, search_engine_id, cse_id, 5)
    Retrieval_content = "é€™æ˜¯ç¶²è·¯ä¸Šæœå°‹åˆ°çš„è³‡æ–™å¯ä¾›åƒè€ƒ:\n"
    for i, result in enumerate(search_results):
        Retrieval_content += f"æ¨™é¡Œï¼š{result['title']}\n"
        Retrieval_content += f"æ‘˜è¦ï¼š{result['snippet']}\n"
        llm_input = f"Prompt:\n{user_query}\n{Retrieval_content[:4000]}"
    # generaiton
    gemini_output = rag_output(llm_input, gemini_key, search_engine_id, cse_id, model_name)
    return gemini_output

st.title("ğŸ’¬  Chatbot")
st.caption("ğŸš€ A Streamlit chatbot powered by gemini and rag")
if 'messages' not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ:"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    response = main_response(prompt)
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
    
    
#streamlit run gemini_rag.py